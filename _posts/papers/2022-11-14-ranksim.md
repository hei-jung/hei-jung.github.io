---
title: "[논문리뷰] RankSim for Deep Imbalanced Regression (2022)"
categories: paper-review
tags: machine-learning python pytorch
use_math: true
---

# RankSim 논문 & 코드 리뷰

[RankSim: Ranking Similarity Regularization for Deep Imbalanced Regression](https://arxiv.org/abs/2205.15236), [Github](https://github.com/BorealisAI/ranksim-imbalanced-regression.git)

## My Preview

### Regularization과 Imbalanced Regression

Regularization이란 weight 값이 너무 커지지 않도록 제한하는 일종의 penalty 조건이다.

한편 regression task가 classification task와 다른 점은 학습 모델이 예측해야 하는 값의 범위가 연속적이라는 것이다.
그래서 imbalanced classification을 위한 method를 regression에 그대로 적용하는 데에는 어려움이 따른다.

전에 정리한 적 있는 [Delving into Deep Imbalanced Regression](https://hei-jung.github.io/paper-review/deep-imbalanced-regression/) 논문에서는 regression 데이터의 연속성을 이용해서 데이터 분포에 따라 loss를 re-weighting 하거나 (LDS), feature 벡터를 보정하는 (FDS) 방법을 소개하였다.
그리고 오늘 리뷰하고자 하는 이 논문은 거기서 확장해서 regularization을 통해 imbalanced regression의 성능을 높이는 방법을 제안하고 있다.

## Introduction

<u>LDS, FDS 등 imbalanced regression 관련 선행 연구와의 차별점:</u> 선행 연구에서는  label space에서 가까이 분포하고 있는 데이터의 관계에 집중하고 있다. RankSim은 label space에서 서로 근처에 있는 데이터 뿐만 아니라 멀리 떨어져 있는 데이터 간의 관계까지 고려하고 있다.

즉 RankSim의 목적은 **label space에서 비슷하면 feature space에서도 비슷하라**는 것이다.

age estimation exampe에서 1, 21, 25, 70살 데이터를 예로 들어보자.<br>
$ \bf{z}^{n} $: label space에서 n살에 해당하는 learned feature<br>
$ \sigma(⋅,⋅) $: 두 벡터 간 similarity function (예: cosine 유사도)<br>
라고 할 때, 21살의 feature인 $ \bf{z}^{21} $에 대해서는 $ \sigma(\bf{z}^{21}, \bf{z}^{25}) > \sigma(\bf{z}^{21}, \bf{z}^{1}) > \sigma(\bf{z}^{21}, \bf{z}^{70}) $를 만족하도록 bias를 줘야 한다.

이걸 그림으로 나타낸 게 Figure 1과 같다.

![Figure1](/assets/images/221114/Figure1.png)

## Methods

이 section에서는 수식을 통해 RankSim의 원리를 좀 더 자세히 설명하고 있다.

$ \bf{a}\in\mathbb{R} $ ($ \bf {a} $는 임의의 실수 n개에 대한 벡터<br>
$ \rm{rk}(\bf{a})_{i} = 1 + |\{j: a_{j} > a_{i}\}| $ (1)

=> 예를 들어 $ \bf{a} = [9,5,11,6] $이면 $ \rm{rk}(\bf{a}) = [2,4,1,3] $이 된다.

(input, label) 데이터 순서쌍을 $ (\bf{x}_i, y_i) $로 표기한다.<br>
$ \theta $를 neural network의 학습 parameter라고 하고 $ \bf{x}의 feature를 $ \bf{z} = f(\bf{x};\theta) $로 나타낸다.<br>
RankSim의 아이디어는 $y$와 $\bf{z}$의 순서를 맞추는 데에서 온다.

$ \sl{M} = \{(\bf{x}_{i}, y_i), i=1,...,M\} $: 데이터 순서쌍에 대한 부분 집합<br>
$ {\bf{S}}_{i,j}^{y} = \sigma^{y}(y_i, y_j)$ (2)
: label space에서 $i$ 데이터와 $j$ 데이터의 유사도 ($ \bf{S}^{y}\in{\mathbb{R}}^{M \times M} $, $ \sigma^{y}: label space에서의 similarity function $)
$ {\bf{S}}_{i,j}^{z} = \sigma^{z}({\bf{z}}_i, {\bf{z}}_j) = \sigma(f({\bf{x}}_i;\theta), f({\bf{x}}_j;\theta)) $ (3)
: feature space에서 $i$ 데이터와 $j$ 데이터의 유사도

이때 $ \sl{M} $에 대하여  RankSim regularization loss를 다음과 같이 정의한다:<br>
$ {\sl{L}}_{\rm{RankSim}} = \sum_{i=1}^{|\sl{M}|} l(\rm{rk}(\bf{S}_{[i,:]}^{y}), \rm{rk}(\bf{S}_{[i,:]}^{z})) $ (4)<br>
여기서 $[i,:]$은 matrix의 i번째 행을 의미하고 $l$은 input 벡터 간 차이에 페널티를 주는 ranking similarity function이다.
$l$에 mean squared error (MSE)를 사용함으로써 label space의 ranking 벡터와 feature space의 ranking 벡터들 간의 Spearman correlation을 최대화 한다. training 과정에서 각 batch로부터 $\sl{M}$을 생성하고, 이를 생성할 때는 각 label의 최대 한 번만 나타나도록 하여 label의 중복을 줄이고 infrequent label과 상대적으로 가까운 값을 좀 더 잘 찾을 수 있게 만든다.

그런데 [ranking loss](https://hei-jung.github.io/paper-review/ranking-loss/)를 다룰 때도 썼지만 ranking 기반 loss는 일부 구간에서 미분이 불가능하기 때문에 모델 최적화에 사용하기 부적절하다. (piecewise constant function라서 거의 모든 구간에서 gradient가 0이 되기 때문.) 그래서 이걸 해결하기 위해 ranking operator를 linear combinatorial objective의 minimizer로 치환한다.

$ {\arg\min}_{\pi\in{\Pi}_n} \bf{a}\cdot{\pi} $ (5)<br>
($ \Pi_n $: $\{1,...,n\}$의 모든 순열에 대한 집합)

여기서 gradient를 얻기 위해 $\lambda > 0$이라는 interpolation hyperparameter를 사용하여 거의 항상 0이 나올 원래의 gradient 대신에 interpolation의 gradient를 계산한다.

$ \frac{\partial {\sl{L}}}{\partial {\bf{a}}} = - \frac{1}{\lambda} (\rm{rk}(\bf{a}) - \rm{rk}({\bf{a}}_{\lambda})) $ (6)<br>
$ {\bf{a}}_{\lambda} = \bf{a} + \lambda \frac{\partial {\sl{L}}}{\parial {\rm{rk}}} $ (7)

이로써 RankSim regularizer를 구현할 수 있고 기존의 training parameter에서 단 두 개의 hyperparameter만이 추가되었다:
$\lambda$: interpolation strength, $\gamma$: balancing weight.

## Experiments

그래서 RankSim을 기존의 imbalanced regression dataset을 가지고 실험해 본 결과 label space에서 인접한 데이터들이 feature space에서도 인접해진 것을 확인할 수 있었다.

![Figure3](/assets/images/221114/Figure3.png)
